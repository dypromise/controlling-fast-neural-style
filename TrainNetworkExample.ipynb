{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-24T09:08:59.791115",
     "start_time": "2016-10-24T09:08:59.770554"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir missing, to get the pretrained models execute the download_leon_models.sh script\n",
      "Data dir missing, for training networks you first need to create a dataset using the make_style_dataset.py script\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import scipy\n",
    "import h5py\n",
    "import skimage\n",
    "import glob\n",
    "from skimage import io,transform \n",
    "from skimage.io import imread,imsave\n",
    "from collections import OrderedDict\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "art_dir = project_dir + '/images/styles/'\n",
    "photo_dir = project_dir + '/images/content/'\n",
    "guide_dir = project_dir + '/images/guides/'\n",
    "out_dir = project_dir + '/images/outputs/'\n",
    "model_dir = project_dir + '/models/trained/'\n",
    "if not os.path.isdir(model_dir):\n",
    "    print('Model dir missing, to get the pretrained models execute the download_leon_models.sh script')\n",
    "data_dir = project_dir + '/data/'\n",
    "if not os.path.isdir(data_dir):\n",
    "    print('Data dir missing, for training networks you first need to create a dataset using the make_style_dataset.py script')\n",
    "tmp_dir = project_dir + '/tmp/'\n",
    "if not os.path.isdir(tmp_dir):\n",
    "    os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train luminance network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For luminance training, one first needs to create a luminance dataset using the '--lum' flag in the make_style_dataset.py script.\n",
    "\n",
    "The code below assumes that the dataset is saved under \"fast-neural-style/data/\" and named \"ms-coco-{data_size}-lum.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define training parameters\n",
    "# arch = 'c9s1-32,d64,d128,R128,R128,R128,R128,R128,u64,u32,c9s1-3'\n",
    "arch = 'c9s1-16,d32,d64,R64,R64,R64,R64,R64,u32,u16,c9s1-3'\n",
    "data_size = 256\n",
    "data_name = str(data_size)+'-lum'\n",
    "loss_network = 'models/vgg16.t7'\n",
    "style_image_size = 256\n",
    "style_weights = '5.0'\n",
    "gpu = 0\n",
    "h5_file = data_dir+'ms-coco-'+data_name+'.h5'\n",
    "style_image = 'candy'\n",
    "num_iterations = 40000\n",
    "checkpoint_name = model_dir + style_image + '_' + data_name+'_guidance_sw_' + style_weights\n",
    "checkpoint_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context = {\n",
    "    'arch': arch,\n",
    "    'h5_file': h5_file,\n",
    "    'loss_network': loss_network,\n",
    "    'style_image': art_dir + style_image + '.jpg',\n",
    "    'style_image_size': style_image_size,\n",
    "    'style_weights': style_weights,\n",
    "    'num_iterations': num_iterations,\n",
    "    'checkpoint_name': checkpoint_name,\n",
    "    'checkpoint_every': checkpoint_every,\n",
    "    'gpu': gpu\n",
    "}\n",
    "\n",
    "template = (\n",
    "            '#!/bin/bash\\n' +\n",
    "            'time /usr/local/torch/install/bin/th train.lua ' + \n",
    "            '-arch {arch} ' +\n",
    "            '-h5_file {h5_file} ' + \n",
    "            '-loss_network {loss_network} ' + \n",
    "            '-style_image {style_image} ' + \n",
    "            '-style_image_size {style_image_size} ' + \n",
    "            '-style_weights {style_weights} ' + \n",
    "            '-checkpoint_name {checkpoint_name} ' + \n",
    "            '-checkpoint_every {checkpoint_every} ' + \n",
    "            '-style_target_type gram ' + \n",
    "            '-gpu {gpu} '\n",
    "           )\n",
    "\n",
    "script_name = project_dir + '/train_fast.sh'\n",
    "with open(script_name, 'w') as script:\n",
    "    script.write(template.format(**context))\n",
    "os.chmod(script_name, 0o755)\n",
    "!{script_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train spatially guided network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network, one first needs to create a dataset using the make_style_dataset.py script.\n",
    "\n",
    "The code below assumes that the dataset is saved under \"fast-neural-style/data/\" and named \"ms-coco-{data_size}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-24T09:16:19.480565",
     "start_time": "2016-10-24T09:16:19.469850"
    }
   },
   "outputs": [],
   "source": [
    "#define training parameters\n",
    "# arch = 'c9s1-32,d64,d128,R128,R128,R128,R128,R128,u64,u32,c9s1-3'\n",
    "arch = 'c9s1-16,d32,d64,R64,R64,R64,R64,R64,u32,u16,c9s1-3'\n",
    "data_size = 256\n",
    "data_name = str(data_size)\n",
    "loss_network = 'models/vgg16.t7'\n",
    "style_image_size = 512\n",
    "style_weights = '5.0'\n",
    "gpu = 0\n",
    "h5_file = data_dir+'ms-coco-'+data_name+'.h5'\n",
    "style_image = 'candy_over_feathers'\n",
    "num_iterations = 40000\n",
    "checkpoint_name = model_dir + style_image + '_' + data_name+'_guidance_sw_' + style_weights\n",
    "checkpoint_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define guidance channels for the style image\n",
    "guide_names = [style_image.replace('.jpg','')+'_candy.jpg',style_image.replace('.jpg','')+'_feathers.jpg']\n",
    "guides = []\n",
    "for name in guide_names:\n",
    "    guides.append(imread(guide_dir + name)[:,:,0])\n",
    "guides = np.dstack(guides).transpose(2,0,1)\n",
    "# save guides \n",
    "guides_file_name = tmp_dir + 'trainguides.hdf5'\n",
    "f = h5py.File(guides_file_name, 'w')\n",
    "f.create_dataset('guides', data=guides)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-24T09:20:33.981699",
     "start_time": "2016-10-24T09:16:22.042721"
    }
   },
   "outputs": [],
   "source": [
    "context = {\n",
    "    'arch': arch,\n",
    "    'h5_file': h5_file,\n",
    "    'loss_network': loss_network,\n",
    "    'style_image': art_dir + style_image + '.jpg',\n",
    "    'style_image_guides': guides_file_name,\n",
    "    'style_image_size': style_image_size,\n",
    "    'style_weights': style_weights,\n",
    "    'num_iterations': num_iterations,\n",
    "    'checkpoint_name': checkpoint_name,\n",
    "    'checkpoint_every': checkpoint_every,\n",
    "    'gpu': gpu\n",
    "}\n",
    "\n",
    "template = (\n",
    "            '#!/bin/bash\\n' +\n",
    "            'time /usr/local/torch/install/bin/th train.lua ' + \n",
    "            '-arch {arch} ' +\n",
    "            '-h5_file {h5_file} ' + \n",
    "            '-loss_network {loss_network} ' + \n",
    "            '-style_image {style_image} ' + \n",
    "            '-style_image_size {style_image_size} ' + \n",
    "            '-style_weights {style_weights} ' + \n",
    "            '-checkpoint_name {checkpoint_name} ' + \n",
    "            '-checkpoint_every {checkpoint_every} ' + \n",
    "            '-style_target_type guided_gram ' + \n",
    "            '-style_image_guides {style_image_guides} ' + \n",
    "            '-gpu {gpu} '\n",
    "           )\n",
    "\n",
    "script_name = project_dir + '/train_fast.sh'\n",
    "with open(script_name, 'w') as script:\n",
    "    script.write(template.format(**context))\n",
    "os.chmod(script_name, 0o755)\n",
    "!{script_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-24T09:23:26.255118",
     "start_time": "2016-10-24T09:23:26.106579"
    }
   },
   "outputs": [],
   "source": [
    "#show training log\n",
    "train_log = checkpoint_name + '.json'\n",
    "with open(train_log) as json_data:\n",
    "    log = json.load(json_data)\n",
    "plt.plot(log['val_loss_history'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
